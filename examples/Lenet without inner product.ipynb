{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f062248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c64926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "caffe_root = '../'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd3db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "Creating lmdb...\n",
      "I20220130 16:06:56.380568 155581952 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb\n",
      "I20220130 16:06:56.381731 155581952 convert_mnist_data.cpp:88] A total of 60000 items.\n",
      "I20220130 16:06:56.381748 155581952 convert_mnist_data.cpp:89] Rows: 28 Cols: 28\n",
      "I20220130 16:06:56.583675 155581952 convert_mnist_data.cpp:108] Processed 60000 files.\n",
      "I20220130 16:06:56.628837 181136896 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb\n",
      "I20220130 16:06:56.629940 181136896 convert_mnist_data.cpp:88] A total of 10000 items.\n",
      "I20220130 16:06:56.629951 181136896 convert_mnist_data.cpp:89] Rows: 28 Cols: 28\n",
      "I20220130 16:06:56.668972 181136896 convert_mnist_data.cpp:108] Processed 10000 files.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# run scripts from caffe root\n",
    "import os\n",
    "os.chdir(caffe_root)\n",
    "# Download data\n",
    "!data/mnist/get_mnist.sh\n",
    "# Prepare data\n",
    "!examples/mnist/create_mnist.sh\n",
    "# back to examples\n",
    "os.chdir('examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b2b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from caffe import layers as L, params as P\n",
    "\n",
    "def lenet(lmdb, batch_size):\n",
    "    # our version of LeNet: a series of linear and simple nonlinear transformations\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,\n",
    "                             transform_param=dict(scale=1./255), ntop=2)\n",
    "    \n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.conv2 = L.Convolution(n.pool1, kernel_size=5, num_output=10, weight_filler=dict(type='xavier'))\n",
    "    n.loss =  L.SoftmaxWithLoss(n.conv2, n.label)\n",
    "    \n",
    "    return n.to_proto()\n",
    "    \n",
    "with open('mnist/lenet_auto_train.prototxt', 'w') as f:\n",
    "    f.write(str(lenet('mnist/mnist_train_lmdb', 64)))\n",
    "    \n",
    "with open('mnist/lenet_auto_test.prototxt', 'w') as f:\n",
    "    f.write(str(lenet('mnist/mnist_test_lmdb', 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a924174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet_gen(lmdb, batch_size):\n",
    "    # our version of LeNet: a series of linear and simple nonlinear transformations\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,\n",
    "                             transform_param=dict(scale=1./255), ntop=2)\n",
    "    \n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.conv2 = L.Convolution(n.pool1, kernel_size=5, num_output=10, weight_filler=dict(type='xavier'))\n",
    "    n.loss =  L.SoftmaxWithLoss(n.conv2, n.label)\n",
    "    \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a1465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\r\n",
      "  name: \"data\"\r\n",
      "  type: \"Data\"\r\n",
      "  top: \"data\"\r\n",
      "  top: \"label\"\r\n",
      "  transform_param {\r\n",
      "    scale: 0.003921568859368563\r\n",
      "  }\r\n",
      "  data_param {\r\n",
      "    source: \"mnist/mnist_train_lmdb\"\r\n",
      "    batch_size: 64\r\n",
      "    backend: LMDB\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv1\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"data\"\r\n",
      "  top: \"conv1\"\r\n",
      "  convolution_param {\r\n",
      "    num_output: 20\r\n",
      "    kernel_size: 5\r\n",
      "    weight_filler {\r\n",
      "      type: \"xavier\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"pool1\"\r\n",
      "  type: \"Pooling\"\r\n",
      "  bottom: \"conv1\"\r\n",
      "  top: \"pool1\"\r\n",
      "  pooling_param {\r\n",
      "    pool: MAX\r\n",
      "    kernel_size: 2\r\n",
      "    stride: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv2\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"pool1\"\r\n",
      "  top: \"conv2\"\r\n",
      "  convolution_param {\r\n",
      "    num_output: 10\r\n",
      "    kernel_size: 5\r\n",
      "    weight_filler {\r\n",
      "      type: \"xavier\"\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"loss\"\r\n",
      "  type: \"SoftmaxWithLoss\"\r\n",
      "  bottom: \"conv2\"\r\n",
      "  bottom: \"label\"\r\n",
      "  top: \"loss\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat mnist/lenet_auto_train.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d41c7f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The train/test net protocol buffer definition\r\n",
      "train_net: \"mnist/lenet_auto_train.prototxt\"\r\n",
      "test_net: \"mnist/lenet_auto_test.prototxt\"\r\n",
      "# test_iter specifies how many forward passes the test should carry out.\r\n",
      "# In the case of MNIST, we have test batch size 100 and 100 test iterations,\r\n",
      "# covering the full 10,000 testing images.\r\n",
      "test_iter: 100\r\n",
      "# Carry out testing every 500 training iterations.\r\n",
      "test_interval: 500\r\n",
      "# The base learning rate, momentum and the weight decay of the network.\r\n",
      "base_lr: 0.01\r\n",
      "momentum: 0.9\r\n",
      "weight_decay: 0.0005\r\n",
      "# The learning rate policy\r\n",
      "lr_policy: \"inv\"\r\n",
      "gamma: 0.0001\r\n",
      "power: 0.75\r\n",
      "# Display every 100 iterations\r\n",
      "display: 100\r\n",
      "# The maximum number of iterations\r\n",
      "max_iter: 10000\r\n",
      "# snapshot intermediate results\r\n",
      "snapshot: 5000\r\n",
      "snapshot_prefix: \"mnist/lenet\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat mnist/lenet_auto_solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e35f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()\n",
    "\n",
    "### load the solver and create train and test nets\n",
    "solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "solver = caffe.SGDSolver('mnist/lenet_auto_solver.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d47c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3697ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef41b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d5341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e113d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143309f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74882f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d724fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf130a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cdb9055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b75450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076da286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0378548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
